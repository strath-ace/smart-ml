{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Sim Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import trange, tnrange\n",
    "\n",
    "from deep_qnet_agent import DQNAgentDemo\n",
    "from environment import Environment, LanderEnvironment\n",
    "from full_lander_sim import *\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_agent(agent, env, fname):\n",
    "    env.reset()\n",
    "    \n",
    "    agentcon = agent_config()\n",
    "    netcon = network_config()\n",
    "    for key in agentcon.keys():\n",
    "        agentcon[key] = getattr(agent, key)\n",
    "    for key in netcon.keys():\n",
    "        netcon[key] = getattr(agent, key)\n",
    "        \n",
    "    netparams = {}\n",
    "    netparams['w_in'] = agent.sess.run(agent.w_in)\n",
    "    netparams['b_in'] = agent.sess.run(agent.b_in)\n",
    "    netparams['W'] = agent.sess.run(agent.W)\n",
    "    agent_data = {'agentcon':agentcon, 'netcon':netcon, 'netparams':netparams,\n",
    "                 'SA':(agent.state_size, agent.action_size), 'env':env}\n",
    "    pickle.dump(agent_data,open(fname,'wb'))\n",
    "    \n",
    "def save_deep_agent(agent, env, fname):\n",
    "    env.reset()\n",
    "    \n",
    "    agentcon = agent_config()\n",
    "    netcon = network_config()\n",
    "    for key in agentcon.keys():\n",
    "        agentcon[key] = getattr(agent, key)\n",
    "    for key in netcon.keys():\n",
    "        netcon[key] = getattr(agent, key)\n",
    "        \n",
    "    netparams = {}\n",
    "    for w in agent.weights.keys():\n",
    "        netparams[w] = agent.sess.run(agent.weights[w])\n",
    "    for b in agent.biases.keys():\n",
    "        netparams[b] = agent.sess.run(agent.biases[b])\n",
    "\n",
    "    agent_data = {'agentcon':agentcon, 'netcon':netcon, 'netparams':netparams,\n",
    "                 'SA':(agent.state_size, agent.action_size), 'env':env}\n",
    "    pickle.dump(agent_data,open(fname,'wb'))\n",
    "    \n",
    "def load_agent(fname):\n",
    "    agent_data = pickle.load(open(fname,'rb'))\n",
    "    env = agent_data['env']\n",
    "    agent = QNetAgent(agent_data['agentcon'],agent_data['netcon'],env)\n",
    "\n",
    "    netparams = agent_data['netparams']\n",
    "    with agent.sess.as_default():\n",
    "        agent.w_in.load(netparams['w_in'])\n",
    "        agent.b_in.load(netparams['b_in'])\n",
    "        agent.W.load(netparams['W'])\n",
    "    print(agent.sess.run(agent.W))\n",
    "    \n",
    "    return agent, env\n",
    "\n",
    "def load_deep_agent(fname):\n",
    "    agent_data = pickle.load(open(fname,'rb'))\n",
    "    env = agent_data['env']\n",
    "    agent = DQNAgentDemo(agent_data['agentcon'],agent_data['netcon'],env,[])\n",
    "\n",
    "    netparams = agent_data['netparams']\n",
    "    with agent.sess.as_default():\n",
    "        for w in agent.weights.keys():\n",
    "            agent.weights[w].load(netparams[w])\n",
    "        for b in agent.biases.keys():\n",
    "            agent.biases[b].load(netparams[b])\n",
    "    return agent, env\n",
    "\n",
    "def reset_agent(agent, netcon, agentcon):\n",
    "    \"\"\"\n",
    "    This function resets an agent's hyperparameters while maintaining its weights\n",
    "    \"\"\"\n",
    "    # Reset hyperparams\n",
    "    for key in agentcon.keys():\n",
    "        setattr(agent, key, agentcon[key])\n",
    "    for key in netcon.keys():\n",
    "        setattr(agent, key, netcon[key])\n",
    "    agent.eps = agent.eps0\n",
    "    \n",
    "    # Assign target network\n",
    "    agent.sess.run(agent.wt_assign)\n",
    "    agent.sess.run(agent.bt_assign)\n",
    "    agent.sess.run(agent.Wt_assign)\n",
    "    \n",
    "    # Memory (maintains state transition memory)\n",
    "    agent.prev_s=[]\n",
    "    agent.prev_a=[]\n",
    "    agent.step_count=0\n",
    "    agent.ep_no=0\n",
    "    \n",
    "    return agent\n",
    "\n",
    "def do_run(agent, env, N_ep):\n",
    "    R_ep = []\n",
    "    t = tnrange(N_ep, desc='bar_desc', leave=True)\n",
    "#     for ep_no in tqdm(range(N_ep)):\n",
    "    for ep_no in t:\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        r = 0\n",
    "        n_step = 0\n",
    "        while not done:\n",
    "            action = agent.action_select(env,observation)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            agent.update_net(observation,reward,done)\n",
    "            r += reward\n",
    "            n_step +=1\n",
    "        R_ep.append(r)\n",
    "        t.set_description('Last reward: {}'.format(r))\n",
    "        t.refresh()\n",
    "    return R_ep, agent, env\n",
    "\n",
    "def agent_demo(agent, env, N_ep):\n",
    "    R_ep = []\n",
    "    for ep_no in tqdm(range(N_ep)):\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        r = 0\n",
    "        while not done:\n",
    "            action = agent.action_select(env,observation)\n",
    "            observation, reward, done, _ = env.step(action)\n",
    "            env.render()\n",
    "            r += reward\n",
    "        R_ep.append(r)\n",
    "    return R_ep\n",
    "\n",
    "def data_smooth(data,n_avg):\n",
    "\t# A function to average data over n_avg timesteps\n",
    "\tind_vec = np.arange(n_avg,len(data)+1,n_avg)\n",
    "\tdata_avg = [0]\n",
    "\tfor ind in ind_vec:\n",
    "\t\tdata_avg.append(np.mean(data[ind-n_avg:ind]))\n",
    "\treturn data_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_heuristic_lander(MarsLander())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "observations: +0.00 -0.00 +0.00 +0.00 -0.00 +0.00 +1.00 +1.00\n",
      "step 1872 total_reward -48.42\n",
      "Episode 1\n",
      "observations: +0.00 -0.00 +0.00 +0.00 -0.00 +0.00 +1.00 +1.00\n",
      "step 1876 total_reward -41.31\n",
      "Episode 1\n",
      "observations: -0.00 -0.00 +0.00 +0.00 +0.00 +0.00 +1.00 +1.00\n",
      "step 1872 total_reward -46.27\n",
      "Episode 1\n",
      "observations: -0.00 -0.00 +0.00 +0.00 +0.00 +0.00 +1.00 +1.00\n",
      "step 1879 total_reward -45.66\n",
      "Episode 1\n",
      "observations: +0.01 -0.00 +0.00 +0.00 -0.00 +0.00 +1.00 +1.00\n",
      "step 1873 total_reward -48.65\n"
     ]
    }
   ],
   "source": [
    "exp_heuristic = exp_heuristic_lander(MarsLander())\n",
    "fname = 'lander_full_heuristic_13_11'\n",
    "np.save(open(fname,'wb'),exp_heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9377, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(exp_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_config():\n",
    "    netcon = {}\n",
    "    netcon['alpha'] = 0.001\n",
    "    netcon['clip_norm'] = 1.0\n",
    "    netcon['update_steps'] = 50\n",
    "    netcon['N_hid_1'] = 120\n",
    "    netcon['N_hid_2'] = 80\n",
    "    netcon['activation'] = 'tanh'\n",
    "    netcon['init_mag'] = 0.01\n",
    "    return netcon\n",
    "\n",
    "def agent_config():\n",
    "    agentcon = {}\n",
    "    agentcon['gamma'] = 0.9\n",
    "    agentcon['eps0'] = 0.5\n",
    "    agentcon['epsf'] = 0.0\n",
    "    agentcon['n_eps'] = 800\n",
    "    agentcon['minib'] = 20\n",
    "    agentcon['minib_demo'] = 50\n",
    "    agentcon['max_mem'] = 500000\n",
    "    return agentcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'lander_full_heuristic_13_11'\n",
    "demo_exp = np.load(open(fname,'rb'),allow_pickle=True).tolist()\n",
    "\n",
    "print(agent_config())\n",
    "print(network_config())\n",
    "\n",
    "mean_end = -500\n",
    "agent_no = 0\n",
    "while mean_end<100:\n",
    "    agent_no+=1\n",
    "    print('Agent ' + str(agent_no))\n",
    "    \n",
    "    N_ep = 600\n",
    "    env = LanderEnvironment()W\n",
    "    agent = QNetAgentDemo(agent_config(),network_config(),env,demo_exp)\n",
    "    \n",
    "    R_ep, agent, env = do_run(agent, env, N_ep)\n",
    "    mean_end = np.mean(R_ep[-100:])\n",
    "    print('R end: ' + repr(mean_end))\n",
    "    \n",
    "    save_agent(agent, env, 'agent'+str(agent_no))\n",
    "    pickle.dump(R_ep, open('reward'+str(agent_no),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'lander_full_heuristic_13_11'\n",
    "demo_exp = np.load(open(fname,'rb'),allow_pickle=True).tolist()\n",
    "\n",
    "env = LanderEnvironment()\n",
    "agent = DQNAgentDemo(agent_config(),network_config(),env,demo_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the deep agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.9, 'eps0': 0.5, 'epsf': 0.0, 'n_eps': 800, 'minib': 20, 'minib_demo': 50, 'max_mem': 500000}\n",
      "{'alpha': 0.001, 'clip_norm': 1.0, 'update_steps': 50, 'N_hid_1': 120, 'N_hid_2': 80, 'activation': 'tanh', 'init_mag': 0.01}\n",
      "Agent 0\n",
      "WARNING:tensorflow:From /home/callum/.local/lib/python3.6/site-packages/tensorflow/python/ops/clip_ops.py:157: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca93fe4a9611429dab5d9bc366362f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='bar_desc', max=1000, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-26625ebcea01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNAgentDemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetwork_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdemo_exp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mR_ep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_ep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mmean_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R end: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-5629bfd49661>\u001b[0m in \u001b[0;36mdo_run\u001b[0;34m(agent, env, N_ep)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mn_step\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/smart-ml/RL-agents/deep_qnet_agent.py\u001b[0m in \u001b[0;36mupdate_net\u001b[0;34m(self, state, reward, done)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;31m#                       self.sess.run(self.bt_assign)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;31m#                       self.sess.run(self.Wt_assign)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/smart-ml/RL-agents/deep_qnet_agent.py\u001b[0m in \u001b[0;36mtarget_assign\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_biases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m#               self.wt_assign = self.wt.assign(self.w_in)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \"\"\"\n\u001b[0;32m--> 731\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5577\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5578\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5579\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fname = 'lander_full_heuristic_13_11'\n",
    "demo_exp = np.load(open(fname,'rb'),allow_pickle=True).tolist()\n",
    "\n",
    "print(agent_config())\n",
    "print(network_config())\n",
    "\n",
    "N_attempt = 20\n",
    "for agent_no in range(N_attempt):\n",
    "    print('Agent ' + str(agent_no))\n",
    "    \n",
    "    N_ep = 1000\n",
    "    env = LanderEnvironment()\n",
    "    agent = DQNAgentDemo(agent_config(),network_config(),env,demo_exp)\n",
    "    \n",
    "    R_ep, agent, env = do_run(agent, env, N_ep)\n",
    "    mean_end = np.mean(R_ep[-100:])\n",
    "    print('R end: ' + repr(mean_end))\n",
    "    \n",
    "    save_deep_agent(agent, env, 'agent'+str(agent_no))\n",
    "    pickle.dump(R_ep, open('reward'+str(agent_no),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92032ce977b548f481865ca9c442b1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R = agent_demo(agent,env,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.gym_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f741bb24940>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.clip_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
